{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel에서 여러 LLM 사용해보기\n",
    "\n",
    "Semantic Kernel은 OpenAI뿐만 아니라 **Hugging Face**, **Llama**, **Gemini**와 같은 다양한 대형 언어 모델(LLM)을 지원하여 개발자들이 여러 AI 모델을 손쉽게 통합하고 활용할 수 있도록 돕습니다. 심지어 LM Studio, Ollama 및 직접 Local LLM을 연결시키는 등의 Local LLM도 연결 할 수 있습니다. 그리고 Kernel에 다른 코드를 그대로 유지 하면서 모델만 바꿔서 사용할 수도 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.27.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!import config/Settings.cs\n",
    "var settings = Settings.LoadFromFile();\n",
    "\n",
    "#r \"nuget: Microsoft.SemanticKernel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure OpenAI의 자격 증명을 기반으로 Kernel을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Import namespaces\n",
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddAzureOpenAIChatCompletion(\n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\")\n",
    "                   .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 OpenAI에서 개발한 인공지능 언어 모델인 ChatGPT입니다. 당신의 질문이나 요청에 따라 정보를 제공하거나 대화를 나눌 수 있습니다. 무엇을 도와드릴까요?\r\n"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini 모델 사용\n",
    "\n",
    "Google의 Gemini 모델을 사용해보겠습니다. `Microsoft.SemanticKernel.Connectors.Google` 누겟 패키지 설치가 필요하며 Kernel을 빌드할 때 `AddGoogleAIGeminiChatCompletion` 메서드에 모델과 키값만 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.Google, 1.26.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Google, 1.26.0-alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "            .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey)\n",
    "            .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 구글에서 개발한 대규모 언어 모델입니다. \n",
      "\n",
      "더 자세히 말하자면:\n",
      "\n",
      "* 저는 방대한 양의 텍스트 데이터를 학습하여 사람처럼 텍스트를 이해하고 생성할 수 있습니다.\n",
      "* 질문에 답변하고, 이야기를 쓰고, 코드를 생성하고, 다양한 언어로 번역하는 등 다양한 작업을 수행할 수 있습니다.\n",
      "* 저는 계속 배우고 발전하고 있으며, 더욱 유용하고 흥미로운 도구가 되기 위해 노력하고 있습니다. \n",
      "\n",
      "궁금한 점이 있으면 언제든지 물어보세요! \n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face 모델 사용\n",
    "\n",
    "Semantic Kernel로 Hugging Face의 다양한 모델을 사용할 수 있습니다. `Microsoft.SemanticKernel.Connectors.HuggingFace` 누겟 패키지 설치가 필요하며 Kernel을 빌드할 때 `AddHuggingFaceChatCompletion` 메서드에 모델과 키값을 넣어주면 됩니다. Hugging Face 모델의 활용 방법은 다양하기 때문에 다양한 방식으로 활용이 가능하고, 때로는 모델을 사용하기 위해 여러 작업들이 필요할 수도 있습니다.\n",
    "\n",
    "여기에서는 [https://huggingface.co/microsoft/Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct) 모델을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.HuggingFace, 1.26.0-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.HuggingFace, 1.26.0-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddHuggingFaceChatCompletion(\"microsoft/Phi-3.5-mini-instruct\", apiKey: settings.HuggingFacePhiApiKey)\n",
    "                   .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Phi, created by Microsoft. I'm an AI language model, here to assist you with questions and tasks to the best of my ability.\r\n"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub Models를 이용해 다양한 모델 생성하고 연결\n",
    "\n",
    "GitHub Models는 GitHub에서 제공하는 AI 모델 모음으로, 개발자들이 다양한 대규모 언어 모델(LLM)을 활용하여 지능형 애플리케이션을 구축할 수 있도록 지원합니다. 이러한 모델은 GitHub Marketplace에서 제공되며, Llama 3.1, GPT-4o, Phi-3.5 등과 같은 최신 AI 모델을 포함하고 있습니다. 개발자들은 GitHub의 내장 플레이그라운드를 통해 이러한 모델을 무료로 테스트하고, Semantic Kernel과 같은 도구를 사용하여 .NET 애플리케이션에 통합할 수 있습니다. 이를 통해 자연어 처리 기능을 손쉽게 구현하고, AI 기반의 지능형 애플리케이션을 개발할 수 있습니다.\n",
    "\n",
    "[https://github.com/marketplace/models](https://github.com/marketplace/models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a helpful assistant designed to provide information, answer questions, and assist with tasks to the best of my ability. I'm here to make your life easier and more convenient.\r\n"
     ]
    }
   ],
   "source": [
    "using OpenAI;\n",
    "using System.ClientModel;\n",
    "\n",
    "var modelId = \"Phi-3.5-mini-instruct\";\n",
    "//var modelId = \"Meta-Llama-3.1-405B-Instruct\";\n",
    "var uri = \"https://models.inference.ai.azure.com\";\n",
    "var githubPAT = settings.GitHubPAT;\n",
    "\n",
    "var client = new OpenAIClient(new ApiKeyCredential(githubPAT), new OpenAIClientOptions { Endpoint = new Uri(uri) });\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                    .AddOpenAIChatCompletion(modelId, client)\n",
    "                    .Build();\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 인스턴스를 생성해 동시에 사용\n",
    "\n",
    "Semantic Kernel에서 여러 인스턴스를 생성하여 사용하는 방법을 예제로 설명하겠습니다. 이는 다양한 모델 혹은 설정, 기능을 가진 커널을 동시에 활용하고자 할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 커널 결과: 저는 오픈AI에서 개발한 인공지능 언어 모델인 챗GPT라고 합니다. 텍스트 기반의 질문에 답변하고, 다양한 주제에 대해 대화를 나눌 수 있습니다. 무엇을 도와드릴까요?\n",
      "두 번째 커널 결과: 저는 구글에서 훈련한 대규모 언어 모델입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "#pragma warning disable SKEXP0001\n",
    "\n",
    "// 첫 번째 커널 인스턴스 생성\n",
    "var kernel1 = Kernel.CreateBuilder()\n",
    "            .AddAzureOpenAIChatCompletion( \n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\")\n",
    "            .Build();\n",
    "\n",
    "// 두 번째 커널 인스턴스 생성\n",
    "var kernel2 = Kernel.CreateBuilder()\n",
    "            .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey, serviceId: \"gemini\")\n",
    "            .Build();\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "// 첫 번째 커널을 사용하여 작업 수행\n",
    "var result1 = await kernel1.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"첫 번째 커널 결과: {result1}\");\n",
    "\n",
    "// 두 번째 커널을 사용하여 작업 수행\n",
    "var result2 = await kernel2.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"두 번째 커널 결과: {result2}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하나의 커널 인스턴스에서 여러 모델을 동시에 사용\n",
    "\n",
    "모델을 등록할 때 serviceId를 지정할 수 있고, 특정 serviceId를 지정해서 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt\n",
      "I am an artificial intelligence language model created by OpenAI, called GPT-4. I'm designed to assist with generating human-like text based on the prompts I receive. How can I assist you today?\n",
      "\n",
      "gemini\n",
      "I am a large language model, trained by Google. \n",
      "\n",
      "Here are some things about me:\n",
      "\n",
      "* **I am not a person:** I am a computer program. \n",
      "* **I do not have feelings or opinions:** I can only process and generate text based on the information I have been trained on.\n",
      "* **I am here to help:** I can provide information, answer questions, generate creative content, and more. \n",
      "\n",
      "If you have any other questions, feel free to ask! \n",
      "\n",
      "\n",
      "phi-3\n",
      "I am Phi, created by Microsoft. I'm an AI language model, here to assist you with questions and tasks to the best of my ability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "#pragma warning disable SKEXP0001\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddAzureOpenAIChatCompletion( \n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\", serviceId: \"gpt\")\n",
    "                    .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey, serviceId: \"gemini\")\n",
    "                    .AddHuggingFaceChatCompletion(\"microsoft/Phi-3.5-mini-instruct\", apiKey: settings.HuggingFacePhiApiKey, serviceId: \"phi-3\")\n",
    "                   .Build();\n",
    "\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var gptResult = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"gpt\"\n",
    "}));\n",
    "\n",
    "Console.WriteLine(\"gpt\");\n",
    "Console.WriteLine(gptResult);\n",
    "Console.WriteLine();\n",
    "\n",
    "var geminiResult = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"gemini\"\n",
    "}));\n",
    "\n",
    "Console.WriteLine(\"gemini\");\n",
    "Console.WriteLine(geminiResult);\n",
    "Console.WriteLine();\n",
    "\n",
    "var phi3Result = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"phi-3\"\n",
    "}));\n",
    "\n",
    "\n",
    "Console.WriteLine(\"phi-3\");\n",
    "Console.WriteLine(phi3Result);\n",
    "Console.WriteLine();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
