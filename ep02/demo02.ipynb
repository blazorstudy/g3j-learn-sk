{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel에서 여러 LLM 사용해보기\n",
    "\n",
    "Semantic Kernel은 OpenAI뿐만 아니라 **Hugging Face**, **Llama**, **Gemini**와 같은 다양한 대형 언어 모델(LLM)을 지원하여 개발자들이 여러 AI 모델을 손쉽게 통합하고 활용할 수 있도록 돕습니다. 심지어 LM Studio, Ollama 및 직접 Local LLM을 연결시키는 등의 Local LLM도 연결 할 수 있습니다. 그리고 Kernel에 다른 코드를 그대로 유지 하면서 모델만 바꿔서 사용할 수도 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.27.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!import config/Settings.cs\n",
    "var settings = Settings.LoadFromFile();\n",
    "\n",
    "#r \"nuget: Microsoft.SemanticKernel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure OpenAI의 자격 증명을 기반으로 Kernel을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Import namespaces\n",
    "using Microsoft.SemanticKernel;\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddAzureOpenAIChatCompletion(\n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\")\n",
    "                   .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "System.UriFormatException: Invalid URI: The format of the URI could not be determined.\r\n   at System.Uri.CreateThis(String uri, Boolean dontEscape, UriKind uriKind, UriCreationOptions& creationOptions)\r\n   at System.Uri..ctor(String uriString)\r\n   at Microsoft.SemanticKernel.AzureOpenAIKernelBuilderExtensions.CreateAzureOpenAIClient(String endpoint, ApiKeyCredential credentials, HttpClient httpClient, String apiVersion)\r\n   at Microsoft.SemanticKernel.AzureOpenAIKernelBuilderExtensions.<>c__DisplayClass0_0.<AddAzureOpenAIChatCompletion>b__0(IServiceProvider serviceProvider, Object _)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite callSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitIEnumerable(IEnumerableCallSite enumerableCallSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite callSite, RuntimeResolverContext context)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceProvider.CreateServiceAccessor(ServiceIdentifier serviceIdentifier)\r\n   at System.Collections.Concurrent.ConcurrentDictionary`2.GetOrAdd(TKey key, Func`2 valueFactory)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetService(ServiceIdentifier serviceIdentifier, ServiceProviderEngineScope serviceProviderEngineScope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetRequiredKeyedService(Type serviceType, Object serviceKey, ServiceProviderEngineScope serviceProviderEngineScope)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceProviderKeyedServiceExtensions.GetRequiredKeyedService[T](IServiceProvider provider, Object serviceKey)\r\n   at System.Linq.Enumerable.SelectManySingleSelectorIterator`2.MoveNext()\r\n   at System.Linq.Enumerable.TryGetLast[TSource](IEnumerable`1 source, Boolean& found)\r\n   at System.Linq.Enumerable.LastOrDefault[TSource](IEnumerable`1 source)\r\n   at Microsoft.SemanticKernel.Services.OrderedAIServiceSelector.<TrySelectAIService>g__GetAnyService|3_0[T](Kernel kernel)\r\n   at Microsoft.SemanticKernel.Services.OrderedAIServiceSelector.TrySelectAIService[T](Kernel kernel, KernelFunction function, KernelArguments arguments, T& service, PromptExecutionSettings& serviceSettings)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.RenderPromptAsync(Kernel kernel, KernelArguments arguments, Boolean isStreaming, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Submission#4.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.UriFormatException: Invalid URI: The format of the URI could not be determined.\r\n",
      "   at System.Uri.CreateThis(String uri, Boolean dontEscape, UriKind uriKind, UriCreationOptions& creationOptions)\r\n",
      "   at System.Uri..ctor(String uriString)\r\n",
      "   at Microsoft.SemanticKernel.AzureOpenAIKernelBuilderExtensions.CreateAzureOpenAIClient(String endpoint, ApiKeyCredential credentials, HttpClient httpClient, String apiVersion)\r\n",
      "   at Microsoft.SemanticKernel.AzureOpenAIKernelBuilderExtensions.<>c__DisplayClass0_0.<AddAzureOpenAIChatCompletion>b__0(IServiceProvider serviceProvider, Object _)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite callSite, RuntimeResolverContext context)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitIEnumerable(IEnumerableCallSite enumerableCallSite, RuntimeResolverContext context)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite callSite, RuntimeResolverContext context)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceProvider.CreateServiceAccessor(ServiceIdentifier serviceIdentifier)\r\n",
      "   at System.Collections.Concurrent.ConcurrentDictionary`2.GetOrAdd(TKey key, Func`2 valueFactory)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetService(ServiceIdentifier serviceIdentifier, ServiceProviderEngineScope serviceProviderEngineScope)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetRequiredKeyedService(Type serviceType, Object serviceKey, ServiceProviderEngineScope serviceProviderEngineScope)\r\n",
      "   at Microsoft.Extensions.DependencyInjection.ServiceProviderKeyedServiceExtensions.GetRequiredKeyedService[T](IServiceProvider provider, Object serviceKey)\r\n",
      "   at System.Linq.Enumerable.SelectManySingleSelectorIterator`2.MoveNext()\r\n",
      "   at System.Linq.Enumerable.TryGetLast[TSource](IEnumerable`1 source, Boolean& found)\r\n",
      "   at System.Linq.Enumerable.LastOrDefault[TSource](IEnumerable`1 source)\r\n",
      "   at Microsoft.SemanticKernel.Services.OrderedAIServiceSelector.<TrySelectAIService>g__GetAnyService|3_0[T](Kernel kernel)\r\n",
      "   at Microsoft.SemanticKernel.Services.OrderedAIServiceSelector.TrySelectAIService[T](Kernel kernel, KernelFunction function, KernelArguments arguments, T& service, PromptExecutionSettings& serviceSettings)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.RenderPromptAsync(Kernel kernel, KernelArguments arguments, Boolean isStreaming, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n",
      "   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Submission#4.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini 모델 사용\n",
    "\n",
    "Google의 Gemini 모델을 사용해보겠습니다. `Microsoft.SemanticKernel.Connectors.Google` 누겟 패키지 설치가 필요하며 Kernel을 빌드할 때 `AddGoogleAIGeminiChatCompletion` 메서드에 모델과 키값만 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.Google, 1.26.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Google, 1.26.0-alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "            .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey)\n",
    "            .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Microsoft.SemanticKernel.HttpOperationException: Response status code does not indicate success: 400 (Bad Request).\r\n ---> System.Net.Http.HttpRequestException: Response status code does not indicate success: 400 (Bad Request).\r\n   at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.Google.Core.ClientBase.SendRequestAndGetStringBodyAsync(HttpRequestMessage httpRequestMessage, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.Google.Core.GeminiChatCompletionClient.SendRequestAndReturnValidGeminiResponseAsync(Uri endpoint, GeminiRequest geminiRequest, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.Google.Core.GeminiChatCompletionClient.GenerateChatMessageAsync(ChatHistory chatHistory, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.GetChatCompletionResultAsync(IChatCompletionService chatCompletion, Kernel kernel, PromptRenderingResult promptRenderingResult, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Submission#6.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Microsoft.SemanticKernel.HttpOperationException: Response status code does not indicate success: 400 (Bad Request).\r\n",
      " ---> System.Net.Http.HttpRequestException: Response status code does not indicate success: 400 (Bad Request).\r\n",
      "   at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n",
      "   --- End of inner exception stack trace ---\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.Google.Core.ClientBase.SendRequestAndGetStringBodyAsync(HttpRequestMessage httpRequestMessage, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.Google.Core.GeminiChatCompletionClient.SendRequestAndReturnValidGeminiResponseAsync(Uri endpoint, GeminiRequest geminiRequest, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.Google.Core.GeminiChatCompletionClient.GenerateChatMessageAsync(ChatHistory chatHistory, PromptExecutionSettings executionSettings, Kernel kernel, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.GetChatCompletionResultAsync(IChatCompletionService chatCompletion, Kernel kernel, PromptRenderingResult promptRenderingResult, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n",
      "   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Submission#6.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face 모델 사용\n",
    "\n",
    "Semantic Kernel로 Hugging Face의 다양한 모델을 사용할 수 있습니다. `Microsoft.SemanticKernel.Connectors.HuggingFace` 누겟 패키지 설치가 필요하며 Kernel을 빌드할 때 `AddHuggingFaceChatCompletion` 메서드에 모델과 키값을 넣어주면 됩니다. Hugging Face 모델의 활용 방법은 다양하기 때문에 다양한 방식으로 활용이 가능하고, 때로는 모델을 사용하기 위해 여러 작업들이 필요할 수도 있습니다.\n",
    "\n",
    "여기에서는 [https://huggingface.co/microsoft/Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct) 모델을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.HuggingFace, 1.26.0-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.HuggingFace, 1.26.0-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddHuggingFaceChatCompletion(\"microsoft/Phi-3.5-mini-instruct\", apiKey: settings.HuggingFacePhiApiKey)\n",
    "                   .Build();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Microsoft.SemanticKernel.HttpOperationException: Response status code does not indicate success: 400 (Bad Request).\r\n ---> System.Net.Http.HttpRequestException: Response status code does not indicate success: 400 (Bad Request).\r\n   at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.HuggingFace.Core.HuggingFaceClient.SendRequestAndGetStringBodyAsync(HttpRequestMessage httpRequestMessage, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.Connectors.HuggingFace.Core.HuggingFaceMessageApiClient.CompleteChatMessageAsync(ChatHistory chatHistory, PromptExecutionSettings executionSettings, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.GetChatCompletionResultAsync(IChatCompletionService chatCompletion, Kernel kernel, PromptRenderingResult promptRenderingResult, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n   at Submission#8.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Microsoft.SemanticKernel.HttpOperationException: Response status code does not indicate success: 400 (Bad Request).\r\n",
      " ---> System.Net.Http.HttpRequestException: Response status code does not indicate success: 400 (Bad Request).\r\n",
      "   at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n",
      "   --- End of inner exception stack trace ---\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, HttpCompletionOption completionOption, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Http.HttpClientExtensions.SendWithSuccessCheckAsync(HttpClient client, HttpRequestMessage request, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.HuggingFace.Core.HuggingFaceClient.SendRequestAndGetStringBodyAsync(HttpRequestMessage httpRequestMessage, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.Connectors.HuggingFace.Core.HuggingFaceMessageApiClient.CompleteChatMessageAsync(ChatHistory chatHistory, PromptExecutionSettings executionSettings, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.GetChatCompletionResultAsync(IChatCompletionService chatCompletion, Kernel kernel, PromptRenderingResult promptRenderingResult, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunctionFromPrompt.InvokeCoreAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.<>c__DisplayClass27_0.<<InvokeAsync>b__0>d.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.SemanticKernel.Kernel.InvokeFilterOrFunctionAsync(NonNullCollection`1 functionFilters, Func`2 functionCallback, FunctionInvocationContext context, Int32 index)\r\n",
      "   at Microsoft.SemanticKernel.Kernel.OnFunctionInvocationAsync(KernelFunction function, KernelArguments arguments, FunctionResult functionResult, Boolean isStreaming, Func`2 functionCallback, CancellationToken cancellationToken)\r\n",
      "   at Microsoft.SemanticKernel.KernelFunction.InvokeAsync(Kernel kernel, KernelArguments arguments, CancellationToken cancellationToken)\r\n",
      "   at Submission#8.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub Models를 이용해 다양한 모델 생성하고 연결\n",
    "\n",
    "GitHub Models는 GitHub에서 제공하는 AI 모델 모음으로, 개발자들이 다양한 대규모 언어 모델(LLM)을 활용하여 지능형 애플리케이션을 구축할 수 있도록 지원합니다. 이러한 모델은 GitHub Marketplace에서 제공되며, Llama 3.1, GPT-4o, Phi-3.5 등과 같은 최신 AI 모델을 포함하고 있습니다. 개발자들은 GitHub의 내장 플레이그라운드를 통해 이러한 모델을 무료로 테스트하고, Semantic Kernel과 같은 도구를 사용하여 .NET 애플리케이션에 통합할 수 있습니다. 이를 통해 자연어 처리 기능을 손쉽게 구현하고, AI 기반의 지능형 애플리케이션을 개발할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "(5,18): error CS0246: 'OpenAIClient' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n(5,35): error CS0246: 'ApiKeyCredential' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n(5,68): error CS0246: 'OpenAIClientOptions' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.",
     "output_type": "error",
     "traceback": [
      "(5,18): error CS0246: 'OpenAIClient' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n",
      "(5,35): error CS0246: 'ApiKeyCredential' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요.\r\n",
      "(5,68): error CS0246: 'OpenAIClientOptions' 형식 또는 네임스페이스 이름을 찾을 수 없습니다. using 지시문 또는 어셈블리 참조가 있는지 확인하세요."
     ]
    }
   ],
   "source": [
    "using OpenAI;\n",
    "using System.ClientModel;\n",
    "\n",
    "var modelId = \"Phi-3.5-mini-instruct\";\n",
    "var uri = \"https://models.inference.ai.azure.com\";\n",
    "var githubPAT = settings.GitHubPAT;\n",
    "\n",
    "var client = new OpenAIClient(new ApiKeyCredential(githubPAT), new OpenAIClientOptions { Endpoint = new Uri(uri) });\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                    .AddOpenAIChatCompletion(modelId, client)\n",
    "                    .Build();\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 인스턴스를 생성해 동시에 사용\n",
    "\n",
    "Semantic Kernel에서 여러 인스턴스를 생성하여 사용하는 방법을 예제로 설명하겠습니다. 이는 다양한 모델 혹은 설정, 기능을 가진 커널을 동시에 활용하고자 할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Input request cancelled",
     "output_type": "error",
     "traceback": [
      "Input request cancelled"
     ]
    },
    {
     "ename": "Error",
     "evalue": "System.Exception: Input request cancelled\r\n   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, Boolean isPassword, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 92\r\n   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 45\r\n   at Submission#10.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.Exception: Input request cancelled\r\n",
      "   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, Boolean isPassword, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 92\r\n",
      "   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 45\r\n",
      "   at Submission#10.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "#pragma warning disable SKEXP0001\n",
    "\n",
    "// 첫 번째 커널 인스턴스 생성\n",
    "var kernel1 = Kernel.CreateBuilder()\n",
    "            .AddAzureOpenAIChatCompletion( \n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\")\n",
    "            .Build();\n",
    "\n",
    "// 두 번째 커널 인스턴스 생성\n",
    "var kernel2 = Kernel.CreateBuilder()\n",
    "            .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey, serviceId: \"gemini\")\n",
    "            .Build();\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "// 첫 번째 커널을 사용하여 작업 수행\n",
    "var result1 = await kernel1.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"첫 번째 커널 결과: {result1}\");\n",
    "\n",
    "// 두 번째 커널을 사용하여 작업 수행\n",
    "var result2 = await kernel2.InvokePromptAsync(prompt);\n",
    "Console.WriteLine($\"두 번째 커널 결과: {result2}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하나의 커널 인스턴스에서 여러 모델을 동시에 사용\n",
    "\n",
    "모델을 등록할 때 serviceId를 지정할 수 있고, 특정 serviceId를 지정해서 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Input request cancelled",
     "output_type": "error",
     "traceback": [
      "Input request cancelled"
     ]
    },
    {
     "ename": "Error",
     "evalue": "System.Exception: Input request cancelled\r\n   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, Boolean isPassword, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 92\r\n   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 45\r\n   at Submission#11.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.Exception: Input request cancelled\r\n",
      "   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, Boolean isPassword, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 92\r\n",
      "   at Microsoft.DotNet.Interactive.Kernel.GetInputAsync(String prompt, String typeHint) in D:\\a\\_work\\1\\s\\src\\Microsoft.DotNet.Interactive\\Kernel.Static.cs:line 45\r\n",
      "   at Submission#11.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "#pragma warning disable SKEXP0070\n",
    "#pragma warning disable SKEXP0001\n",
    "\n",
    "var kernel = Kernel.CreateBuilder()\n",
    "                   .AddAzureOpenAIChatCompletion( \n",
    "                       endpoint: settings.AzureOpenAIEndpoint,\n",
    "                       apiKey: settings.AzureOpenAIApiKey,\n",
    "                       deploymentName:  \"gpt-4o\", serviceId: \"gpt\")\n",
    "                    .AddGoogleAIGeminiChatCompletion(\"gemini-1.5-flash\", settings.GoogleGeminiKey, serviceId: \"gemini\")\n",
    "                    .AddHuggingFaceChatCompletion(\"microsoft/Phi-3.5-mini-instruct\", apiKey: settings.HuggingFacePhiApiKey, serviceId: \"phi-3\")\n",
    "                   .Build();\n",
    "\n",
    "\n",
    "var prompt = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Prompt\");\n",
    "\n",
    "var gptResult = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"gpt\"\n",
    "}));\n",
    "\n",
    "Console.WriteLine(\"gpt\");\n",
    "Console.WriteLine(gptResult);\n",
    "Console.WriteLine();\n",
    "\n",
    "var geminiResult = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"gemini\"\n",
    "}));\n",
    "\n",
    "Console.WriteLine(\"gemini\");\n",
    "Console.WriteLine(geminiResult);\n",
    "Console.WriteLine();\n",
    "\n",
    "var phi3Result = await kernel.InvokePromptAsync(prompt, new(new PromptExecutionSettings()\n",
    "{\n",
    "    ServiceId = \"phi-3\"\n",
    "}));\n",
    "\n",
    "\n",
    "Console.WriteLine(\"phi-3\");\n",
    "Console.WriteLine(phi3Result);\n",
    "Console.WriteLine();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
